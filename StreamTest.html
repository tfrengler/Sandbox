<!DOCTYPE html>
<html>

	<head>
		<title>StreamReader</title>
		<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
		<meta name="author" content="Thomas Frengler" />
	
        <script type="text/javascript">

            const FETCH_ENTRY_POINT = "GetAudio.cfm";
            const STREAM_THROTTLE = 2000; // ms
            const CHUNK_SIZE = 512 * 1000; // Kb
            const WAIT_FOR_BUFFER_UPDATE = 200; // ms

            var streamResponse = {};
            var playing = false;
            var lastPlaytimeUpdate = 0.0; // performance.now() timestamp of last time the current time of the media was updated
            var estimatedDuration = 0; // the AUDIO_FACADE won't get a .duration set until its sourceBuffer stream is closed so we store an estimate here
            var endOfStreamIntervalID = null;
            var abortStream = false;
            var requestByteOffset = 0;
            var streamingStarted = false;

            const AUDIO_FACADE = new Audio();
            AUDIO_FACADE.setAttribute("preload", "metadata");

            const MEDIA_SOURCE = new MediaSource();
            AUDIO_FACADE.src = URL.createObjectURL(MEDIA_SOURCE);

            MEDIA_SOURCE.addEventListener('sourceopen', function() {
                console.log("Media source ready to receive buffers");
                
                const SOURCE_BUFFER = MEDIA_SOURCE.addSourceBuffer("audio/mpeg");

                SOURCE_BUFFER.addEventListener('update', ()=>{
                    console.log("Updated the sourceBuffer");

                    if (estimatedDuration)
                        return;

                    estimatedDuration = -1;
                    calculateDuration(false);
                });
            });

            const wait = function(ms) {
                return new Promise((resolve, reject)=> setTimeout(resolve, parseFloat(ms) || 0));
            };

            const updateInterface = function() {
                document.getElementById("secondsBuffered").innerText = getBufferedDuration() || NaN;
                document.getElementById("bytesBuffered").innerText = streamResponse.status.getBufferedBytes();
                document.getElementById("buffer").value = streamResponse.status.getBufferedPercentage();
                document.getElementById("bufferPercentage").innerText = `${Math.ceil(streamResponse.status.getBufferedPercentage())}%`;
            };

            const getBufferedDuration = function() {
                if (AUDIO_FACADE.buffered.length === 0)
                    return 0;

                const start = AUDIO_FACADE.buffered.start(0);
                const end = AUDIO_FACADE.buffered.end(0);
                var bufferedDuration = 0;

                if (start > 0)
                    bufferedDuration = (end - start);

                bufferedDuration = end;
                return (bufferedDuration > 0 ? bufferedDuration : 0);
            };

            const onStreamUpdate = function() {
                updateInterface();
                console.log(`Seconds buffered: ${getBufferedDuration()}`);
            };

            const calculateBufferedBytes = function() {
                let finalBufferedSize = 0;
                streamResponse.chunks.forEach((value)=>{
                    finalBufferedSize = (finalBufferedSize + value.byteLength);
                });
                return finalBufferedSize || -1;
            };

            const calculateDuration = function(final) {
                if (final && AUDIO_FACADE.duration) {
                    document.getElementById("duration").innerText = `${Math.ceil(AUDIO_FACADE.duration)} seconds (final)`;
                    return;
                };

                const start = AUDIO_FACADE.buffered.start(0);
                const end = AUDIO_FACADE.buffered.end(0);
                var bufferedDuration = 0;

                if (start > 0)
                    bufferedDuration = (end - start);

                bufferedDuration = end;
                let bytesPerSecond = CHUNK_SIZE / bufferedDuration;
                estimatedDuration = streamResponse.size / bytesPerSecond;
                
                console.warn(`Initial estimated duration of media is ${estimatedDuration} seconds`);
                document.getElementById("duration").innerText = `${Math.ceil(estimatedDuration)} seconds (estimate)`;
            };

            const prepareStreamResponse = function(contentSize) {
                streamResponse = Object.create(null);

                streamResponse.size = parseInt(contentSize) || 0;
                // We floor the expected chunks so that the final chunk contains the chunk size plus whatever is left of the content
                streamResponse.chunksExpected = Math.floor(streamResponse.size / CHUNK_SIZE);
                streamResponse.chunks = [];

                streamResponse.status = Object.create(null);
                streamResponse.status.complete = ()=> (streamResponse.chunks.length === streamResponse.chunksExpected);
                streamResponse.status.currentChunk = 0;
                streamResponse.status.getBufferedBytes = calculateBufferedBytes;
                streamResponse.status.started = ()=> streamResponse.chunks.length > 0;
                streamResponse.status.lastUpdate = 0.0;
                streamResponse.status.getBufferedPercentage = function() {return this.getBufferedBytes() / streamResponse.size * 100};

                Object.seal(streamResponse.status);
                Object.freeze(streamResponse);

                document.getElementById("contentSize").innerText = streamResponse.size;

                return streamResponse;
            };
                        
			const getTrackChunk = function(byteStart, byteEnd) {

                if ((isNaN(parseInt(byteStart)) || parseInt(byteStart) < 0) && !parseInt(byteEnd)) {
                    console.error("Can't fetch data chunk. One or more argument is invalid:");
                    console.log(arguments);
                    return false;
                };

                const headers = new Headers();
                headers.append("Accept", "audio/mpeg");
                headers.append("range", `bytes=${byteStart}-${byteEnd}`);

                const requestArguments = {
                    method: "GET",
                    cache: "no-store",
                    mode: "cors",
                    headers: headers
                };

                const request = new Request(FETCH_ENTRY_POINT, requestArguments);
                console.log(`Fetching data chunk: byte start: ${byteStart} | byte end: ${byteEnd} | size: ${byteEnd-byteStart}`);

                return window.fetch(request)
                .then((responseObject)=> {
                    console.log("Converting response to arraybuffer");
                    return responseObject.arrayBuffer();
                })
                .then((decodedResponse)=>{
                    return decodedResponse;
                });

            };

            const inspectMedia = function() {

                const headers = new Headers();
                headers.append("Accept", "audio/mpeg");

                const requestArguments = {
                    method: "HEAD",
                    cache: "no-store",
                    mode: "cors", // TODO(thomas): debug code to remove
                    headers: headers
                };

                const request = new Request(FETCH_ENTRY_POINT, requestArguments);
                return window.fetch(request).then((response)=>{
                    
                    let responseHeaders = Object.create(null);
                    response.headers.forEach((value, key)=>{
                        responseHeaders[key] = value;
                    });
                    return responseHeaders;

                })
            };

            const onStreamEnd = function() {
                updateInterface();

                if (MEDIA_SOURCE.readyState === "ended")
                    return;

                console.log("Closing stream");

                MEDIA_SOURCE.endOfStream();
                streamingStarted = false;
                calculateDuration(true);
            };

            const throttleAndRecurseStreaming = function() {
                let updated = performance.now();
                let updateDifference = updated - streamResponse.status.lastUpdate;
                let throttleReason = 0;

                if (updateDifference < STREAM_THROTTLE)
                    throttleReason = 1;
                else if (MEDIA_SOURCE.sourceBuffers[0].updating)
                    throttleReason = 2;

                if (throttleReason === 1) {
                    console.warn(`Stream updated less than ${STREAM_THROTTLE}ms ago (${Math.ceil(updateDifference)}ms), throttling`);
                    wait(STREAM_THROTTLE).then(()=>throttleAndRecurseStreaming());
                    return;
                };
                
                if (throttleReason === 2) {
                    console.warn("Source buffer is still having the latest audio data appended, waiting");
                    wait(WAIT_FOR_BUFFER_UPDATE).then(()=>throttleAndRecurseStreaming());
                    return;
                }

                streamResponse.status.lastUpdate = updated;
                streamTrack();
            };

            const init = function() {

                AUDIO_FACADE.addEventListener("progress", onStreamUpdate);

                AUDIO_FACADE.addEventListener("canplay", ()=> {
                    console.log("AUDIO_FACADE: Have enough data to start playing");
                    if (!playing)
                        AUDIO_FACADE.play();
                });

                AUDIO_FACADE.addEventListener("error", ()=> {
                    console.error(AUDIO_FACADE.error);
                    abortStream = true;
                });

                AUDIO_FACADE.addEventListener("stalled", ()=> {
                    console.log(`AUDIO_FACADE: Stalled (${AUDIO_FACADE.readyState})`);
                    playing = false;
                });

                AUDIO_FACADE.addEventListener("ended", ()=> {
                    console.log(`AUDIO_FACADE: Current time ${AUDIO_FACADE.currentTime}`);
                    playing = false;
                });

                AUDIO_FACADE.addEventListener("timeupdate", ()=> {
                    if (performance.now() - lastPlaytimeUpdate < 1000)
                        return;

                    document.getElementById("playTime").innerText = Math.ceil(AUDIO_FACADE.currentTime);
                });

                MEDIA_SOURCE.addEventListener("sourceended", function() {
                    console.warn("Media source closed. No further data can be appended");
                });

                document.getElementById("play").addEventListener("click", play);
                document.getElementById("pause").addEventListener("click", ()=> AUDIO_FACADE.pause());

                inspectMedia().then((headers)=>{ prepareStreamResponse(headers["content-length"]) });
            };

            const play = function() {
                if (streamingStarted) {
                    AUDIO_FACADE.play();
                    return;
                };

                streamTrack();
                streamingStarted = true;
            };

            const streamTrack = function() {
                if (abortStream)
                    return console.warn("STREAM ABORTED");

                // TODO(thomas): Debugging, for controlling how many chunks we stream before stopping
                // if (streamResponse.status.currentChunk > 2)
                //     return;

                if (!streamResponse.size && !streamResponse.chunksExpected) {
                    console.warn("streamResponse.size or streamResponse.chunksExpected are not defined or valid;");
                    return false;
                };

                // Check if we are done or not
                if (streamResponse.status.complete()) {

                    if (MEDIA_SOURCE.sourceBuffers[0].updating) {
                        console.warn("Waiting for sourceBuffer update before we can close the stream and calculate the final duration");

                        endOfStreamIntervalID = setInterval(()=>{

                            if (!MEDIA_SOURCE.sourceBuffers[0].updating) {
                                onStreamEnd();
                                clearInterval(endOfStreamIntervalID);
                            };

                        }, 500);
                        return true;
                    };

                    onStreamEnd();
                    return true;
                };

                console.warn(`Fetching chunk ${(streamResponse.status.currentChunk + 1)} out of ${streamResponse.chunksExpected}`);

                let nextChunkByteStart = (streamResponse.status.currentChunk * CHUNK_SIZE) + requestByteOffset;
                let nextChunkByteEnd = 0;

                if (streamResponse.status.currentChunk === (streamResponse.chunksExpected - 1))
                    nextChunkByteEnd = ""; // For the last chunk we just get whatever remains. If we fetch really tiny chunks we may not have enough valid frame data for the decoder
                else
                    nextChunkByteEnd = nextChunkByteStart + CHUNK_SIZE;

                // Function call that returns a promise and is thus async from this point on. streamTrack() exits as soon as this call takes place
                getTrackChunk(nextChunkByteStart, nextChunkByteEnd).then((arrayBufferAudioData)=>{
                    
                    const SOURCE_BUFFER = MEDIA_SOURCE.sourceBuffers[0];
        
                    streamResponse.chunks.push(arrayBufferAudioData);
                    streamResponse.status.currentChunk++;

                    if (arrayBufferAudioData.byteLength > CHUNK_SIZE && !streamResponse.status.complete()) {
                        let audioDataOffset = arrayBufferAudioData.byteLength - CHUNK_SIZE;
                        requestByteOffset = (audioDataOffset + requestByteOffset);
                        console.warn(`AudioData byte length is greater than the requested amount (${CHUNK_SIZE}) by ${audioDataOffset} byte(s). Adjusting the next chunk byte offset to ${requestByteOffset} byte(s)`);
                    };

                    console.log("Appending audio buffer with byte length: " + arrayBufferAudioData.byteLength);
                    // TODO(thomas): Figure out how to deal with files larger than 10MB for the sourceBuffer
                    // Chrome has a limit of 10MB for audio data per source buffer
                    // Probably need some mechanism that removes data from behind where the current play time is
                    // Which means decoupling the concurrent streamResponse- and sourceBuffer manipulation we use now... ugh
                    SOURCE_BUFFER.appendBuffer(arrayBufferAudioData);

                    throttleAndRecurseStreaming();
                })
                .catch((error)=>{console.error(error)});
            };

            window.onload = ()=> {
                init();
                console.log("Ready cap'n!");
            };

		</script>
	</head>

	<body>

        <section>
            <span>BUFFER: </span>
            <span><progress id="buffer" value="0" max="100" ></progress> <span id="bufferPercentage">0%</span></span>
            <ul>

                <li>Content size: <span id="contentSize"></span></li>
                <br/>
                <li>Duration: <span id="duration">Unknown</span></li>
                <li>Current time: <span id="playTime">0</span></li>
                <br/>
                <li>Seconds buffered: <span id="secondsBuffered">0</span></li>
                <li>Bytes buffered: <span id="bytesBuffered">0</span></li>
                
            </ul>

            <span><button id="play" >PLAY/RESUME</button></span>
            <span> | </span>
            <span><button id="pause" >PAUSE</button></span>
        </section>
		
	</body>
</html>